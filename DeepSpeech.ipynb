{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepSpeech.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUuabn50wk9n",
        "colab_type": "code",
        "outputId": "5ac9dd2e-b8b1-415e-b8d1-87d0cf98b018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOHmwgaIxBw-",
        "colab_type": "code",
        "outputId": "8374ab29-efa3-4606-da28-ed4f461a72fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "!pip install deepspeech==0.6.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepspeech==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/f4/1ef0397097e8a8bbb7e24caabecbdb226b4e027e5018e9353ef65af14672/deepspeech-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (9.6MB)\n",
            "\u001b[K     |████████████████████████████████| 9.6MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from deepspeech==0.6.0) (1.18.4)\n",
            "Installing collected packages: deepspeech\n",
            "Successfully installed deepspeech-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olmIu2WpxURq",
        "colab_type": "code",
        "outputId": "08d70038-5ab0-4bd6-fb33-c5bfecaa16d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/deepspeech-0.6.0-models.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   641  100   641    0     0   2811      0 --:--:-- --:--:-- --:--:--  2811\n",
            "100 1172M  100 1172M    0     0  71.3M      0  0:00:16  0:00:16 --:--:-- 82.9M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7SC8w0fxg9h",
        "colab_type": "code",
        "outputId": "f0f61739-5b98-4c63-a5ca-5d99f722e952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!tar -xvzf deepspeech-0.6.0-models.tar.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deepspeech-0.6.0-models/\n",
            "deepspeech-0.6.0-models/lm.binary\n",
            "deepspeech-0.6.0-models/output_graph.pbmm\n",
            "deepspeech-0.6.0-models/output_graph.pb\n",
            "deepspeech-0.6.0-models/trie\n",
            "deepspeech-0.6.0-models/output_graph.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdmPs8l_xro7",
        "colab_type": "code",
        "outputId": "c0f45983-560f-4f64-a697-f406ead15ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!ls -l ./deepspeech-0.6.0-models/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1350664\n",
            "-rw-r--r-- 1 501 staff 945699324 Dec  3 06:51 lm.binary\n",
            "-rw-r--r-- 1 501 staff 188914896 Dec  3 09:03 output_graph.pb\n",
            "-rw-r--r-- 1 501 staff 188915850 Dec  3 09:49 output_graph.pbmm\n",
            "-rw-r--r-- 1 501 staff  47335752 Dec  3 09:05 output_graph.tflite\n",
            "-rw-r--r-- 1 501 staff  12200736 Dec  3 06:51 trie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kRiJCW1xvsb",
        "colab_type": "code",
        "outputId": "02ab3dd1-4aa9-45ef-d9b0-cf065f66f9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.0/audio-0.6.0.tar.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   629  100   629    0     0   2885      0 --:--:-- --:--:-- --:--:--  2898\n",
            "100  192k  100  192k    0     0   331k      0 --:--:-- --:--:-- --:--:--  331k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7OBx6wcxzsv",
        "colab_type": "code",
        "outputId": "be241716-dffb-40cb-e40a-dce5fe99b26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!tar -xvzf audio-0.6.0.tar.gz\n",
        "!ls ./audio/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "audio/\n",
            "audio/2830-3980-0043.wav\n",
            "audio/Attribution.txt\n",
            "audio/4507-16021-0012.wav\n",
            "audio/8455-210777-0068.wav\n",
            "audio/License.txt\n",
            "2830-3980-0043.wav   8455-210777-0068.wav  License.txt\n",
            "4507-16021-0012.wav  Attribution.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXzE17Itx7Ki",
        "colab_type": "code",
        "outputId": "00a11f07-7261-466c-9e5f-19dc37caa204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "!deepspeech --model deepspeech-0.6.0-models/output_graph.pb --lm deepspeech-0.6.0-models/lm.binary --trie ./deepspeech-0.6.0-models/trie --audio ./audio/4507-16021-0012.wav"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file deepspeech-0.6.0-models/output_graph.pb\n",
            "TensorFlow: v1.14.0-21-ge77504a\n",
            "DeepSpeech: v0.6.0-0-g6d43e21\n",
            "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
            "2020-05-28 15:00:21.969765: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "Loaded model in 0.139s.\n",
            "Loading language model from files deepspeech-0.6.0-models/lm.binary ./deepspeech-0.6.0-models/trie\n",
            "Loaded language model in 0.000275s.\n",
            "Running inference.\n",
            "why should one halt on the way\n",
            "Inference took 3.227s for 2.735s audio file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlXV9XlpP8k2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import deepspeech"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLemTTHyyZxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file_path = 'deepspeech-0.6.0-models/output_graph.pbmm'\n",
        "beam_width = 500\n",
        "model = deepspeech.Model(model_file_path, beam_width)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STgEzBRZydAG",
        "colab_type": "code",
        "outputId": "060ffc74-8e39-4ffd-b5c5-ac3636f6ef2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lm_file_path = 'deepspeech-0.6.0-models/lm.binary'\n",
        "trie_file_path = 'deepspeech-0.6.0-models/trie'\n",
        "lm_alpha = 0.75\n",
        "lm_beta = 1.85\n",
        "model.enableDecoderWithLM(lm_file_path, trie_file_path, lm_alpha, lm_beta)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvFlGiaiyg1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wave\n",
        "filename = 'audio/The Euclid Alternative (2).wav'\n",
        "w = wave.open(filename, 'r')\n",
        "rate = w.getframerate()\n",
        "frames = w.getnframes()\n",
        "buffer = w.readframes(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAZqH7Fryojm",
        "colab_type": "code",
        "outputId": "e147a694-57da-4cc0-9dc2-6c222d809d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(rate)\n",
        "print(model.sampleRate())\n",
        "print(str(type(buffer)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16000\n",
            "16000\n",
            "<class 'bytes'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a_eHhQUypVl",
        "colab_type": "code",
        "outputId": "713383e1-cb12-473d-f7fb-e1c64622f2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "data16 = np.frombuffer(buffer, dtype=np.int16)\n",
        "print(str(type(data16)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cb9PB47yr6k",
        "colab_type": "code",
        "outputId": "3818c503-99bf-4a7f-dd85-4c9b0c9de49e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text = model.stt(data16)\n",
        "print(text)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "not at morning letter ah it were going to have to stop my potery bar on the way to work i bought the star war sheets but they can not be much too stimulating to be compatible with a good night's sleep i don't like the way dark later stairs at me i'm not going to work just because your cures been stagnant for a few years as any reason to give up the man i was up all night using the new free electron laser for my extra to fracture to the later exactly burn out her redness and you can drive let's go \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}